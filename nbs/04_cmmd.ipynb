{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CmmD: Continual Multiplex network Module Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python implementation of the algorithm originally proposed in [\"The multilayer community structure of medulloblastoma\" by Iker Núñez-Carpintero et. al.](https://www.sciencedirect.com/science/article/pii/S2589004221003333).\n",
    "\n",
    "Implementation relies on [MolTi-DREAM](https://github.com/gilles-didier/MolTi-DREAM) for communities detection problem.\n",
    "\n",
    "* Make sure to add molti-console as an executable program from any directory by adding it to your ~/.bashrc file. (This file may change depending on your OS ditribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cmmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import libraries and define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary function to measure the execution time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_it(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "        minutes = int(execution_time // 60)\n",
    "        seconds = execution_time % 60\n",
    "        print(f\"Function '{func.__name__}' executed in {minutes} minutes, {seconds:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define function for community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@time_it\n",
    "def communities_detection(input_layers:list[str]=None,\n",
    "                          gamma_min:float=None,\n",
    "                          gamma_max:float=None,\n",
    "                          gamma_step:float=None,\n",
    "                          path_to_communities:str=None,\n",
    "                          method:str=\"molti\"):\n",
    "    # Prepare inputs to generate the console order for MolTi's run.\n",
    "    layers = \" \".join(input_layers)\n",
    "    \n",
    "    resolution_gamma_step = np.arange(gamma_min, gamma_max + gamma_step, gamma_step)\n",
    "    desfile_vector = [f\"{path_to_communities}{res}.csv\" for res in resolution_gamma_step]\n",
    "    \n",
    "    # community analysis\n",
    "    if method == \"molti\":\n",
    "        for i, current_resolution in enumerate(resolution_gamma_step):\n",
    "            current_destfile = desfile_vector[i]\n",
    "            system_order = f\"molti-console -o {current_destfile} -p {current_resolution} {layers} > /dev/null\"\n",
    "            subprocess.run(system_order, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@time_it\n",
    "def continual_multiplex_analysis(nodelist:list[str]=None,\n",
    "                                 path_to_communities:str=None,\n",
    "                                 distmethod:str=\"hamming\",\n",
    "                                 n_jobs:int=1):\n",
    "        # reading MolTi output files\n",
    "        output_files = [f for f in os.listdir(path_to_communities) if \"_\" not in f]\n",
    "        \n",
    "        alllists = []\n",
    "        \n",
    "        for output_file in output_files:\n",
    "            with open(os.path.join(path_to_communities, output_file), 'r') as file:\n",
    "                red = file.readlines()\n",
    "            \n",
    "            cluster_ids = [i for i, line in enumerate(red) if \"Cluster\" in line]\n",
    "            lista = []\n",
    "            \n",
    "            for j, st in enumerate(cluster_ids):\n",
    "                if j == len(cluster_ids) - 1:\n",
    "                    en = len(red)\n",
    "                else:\n",
    "                    en = cluster_ids[j + 1]\n",
    "                current_cluster = red[st:en]\n",
    "                current_cluster2 = current_cluster[:-2] if j != len(cluster_ids) - 1 else current_cluster[:-1]\n",
    "                lista.append(current_cluster2[1:])\n",
    "            \n",
    "            alllists.append(lista)\n",
    "        \n",
    "        allgenes = list(set([gene for sublist in alllists for cluster in sublist for gene in cluster]))\n",
    "\n",
    "        if nodelist:\n",
    "            allgenes = list(set(allgenes).intersection(nodelist))\n",
    "        \n",
    "        # Calculating Gene/Community matrix\n",
    "        res_matrix = np.empty((len(allgenes), len(alllists) + 1), dtype=object)\n",
    "        res_matrix[:, :-1] = 0  # Initialize the integer part of the matrix with zeros\n",
    "        gene_indices = {gene: idx for idx, gene in enumerate(allgenes)}\n",
    "        \n",
    "        for j, output_file_list in enumerate(alllists):\n",
    "            for k, cluster in enumerate(output_file_list):\n",
    "                for gene in cluster:\n",
    "                    res_matrix[gene_indices[gene], j] = k + 1\n",
    "        \n",
    "        patterns = [\"_\".join(map(str, res_matrix[i, :-1])) for i in range(len(allgenes))]\n",
    "        res_matrix[:, -1] = np.array(patterns, dtype=str)\n",
    "        \n",
    "        # Calculating Hamming distances for all gene pairs\n",
    "        gene_community_matrix = res_matrix[:, :-1].astype(np.int64)\n",
    "        genes_same_communities = {pattern: [] for pattern in np.unique(gene_community_matrix[:,-1])}\n",
    "        \n",
    "        for i, pattern in enumerate(gene_community_matrix[:,-1]):\n",
    "            genes_same_communities[pattern].append(allgenes[i])\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "            distance_matrix = squareform(pdist(gene_community_matrix, metric=distmethod))\n",
    "        \n",
    "        final_output = {\n",
    "            \"gene_community_matrix\": gene_community_matrix,\n",
    "            \"l_constant\": genes_same_communities,\n",
    "            \"distance_matrix\": distance_matrix\n",
    "        }\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cmmd(nodelist:list[str]|None=None,\n",
    "         input_layers:list[str]=None,\n",
    "         gamma_min:float=None,\n",
    "         gamma_max:float=None,\n",
    "         gamma_step:float=None, \n",
    "         distmethod:str=\"hamming\",\n",
    "         method:str=\"molti\",\n",
    "         n_jobs:int=1,\n",
    "         path_to_communities:str=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute CmmD multilayer community trajectory analysis for a set of given networks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nodelist : list, optional\n",
    "        A list with the unique nodes that we want to appear in the final output. If not given,\n",
    "        all nodes of the multiplex will be in the final output (nodelist= NULL)\n",
    "    input_layers : list\n",
    "        A vector of strings containing the paths where the different network layers are located\n",
    "        in the system. Networks should be a two column file representing the edges of the graph.\n",
    "    gamma_min : float\n",
    "        The first gamma resolution parameter to use in the different MolTi's analysis\n",
    "    gamma_max : float\n",
    "        The last gamma resolution parameter to use in the different MolTi's analysis.\n",
    "    gamma_step : float\n",
    "        The gamma_step of the resolution parameter to use. \n",
    "    distmethod : str, optional\n",
    "        A distance method metric to use to compute the trajectories. Defaults to \"hamming\" for hamming\n",
    "        distance, but accepts any other metric supplied by scipy.spatial.distance.pdist.\n",
    "    n_jobs : int, optional\n",
    "        The number of n_jobs to use for the computation of the distance matrix. Defaults to 1.\n",
    "    path_to_communities : str, optional\n",
    "        The path to save Molti's output files. Defaults to \"Output/\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary containing the following keys:\n",
    "        gene_community_matrix: A matrix where the rows correspond to the different genes, and the columns to the different community structures. The values of the matrix are the cluster to which the gene belongs in the corresponding community structure.\n",
    "        l_constant: A dictionary where the keys are the different community structures, and the values are the list of genes that belong to that community structure.\n",
    "        distance_matrix: A matrix with the hamming distances between all pairs of genes.\n",
    "    \"\"\"\n",
    "    # 0. check input correctness\n",
    "    if input_layers is None or len(input_layers) < 1:\n",
    "        raise ValueError(\"ERROR: Input_layers argument must be a list of at least 1 network file\")\n",
    "    \n",
    "    if not isinstance(gamma_max, (int, float)):\n",
    "        raise ValueError(\"ERROR: Resolution parameter must be a number\")\n",
    "    \n",
    "    if not isinstance(gamma_min, (int, float)):\n",
    "        raise ValueError(\"ERROR: Resolution parameter must be a number\")\n",
    "    \n",
    "    if not isinstance(gamma_step, (int, float)):\n",
    "        raise ValueError(\"ERROR: gamma_step value must be a number\")\n",
    "    \n",
    "    if not isinstance(path_to_communities, str):\n",
    "        raise ValueError(\"ERROR: path_to_communities expects a character string\")\n",
    "    \n",
    "    assert distmethod in ['braycurtis', 'canberra', 'chebyshev', 'cityblock',\n",
    "                          'correlation', 'cosine', 'dice', 'euclidean', 'hamming',\n",
    "                          'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis',\n",
    "                          'matching', 'minkowski', 'rogerstanimoto', 'russellrao',\n",
    "                          'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n",
    "                          'yule']\n",
    "    \n",
    "    if not isinstance(n_jobs, int):\n",
    "        raise ValueError(\"ERROR: n_jobs must be a number corresponding to the number of cores available to use\")\n",
    "\n",
    "    # 1st part: community detection\n",
    "    Path(path_to_communities).mkdir(parents=True, exist_ok=True)\n",
    "    # if folder is empty, generate communities to populate it\n",
    "    if len(os.listdir(path_to_communities)) == 0:\n",
    "        communities_detection(input_layers=input_layers, gamma_min=gamma_min, gamma_max=gamma_max,\n",
    "                            gamma_step=gamma_step, method=method, path_to_communities=path_to_communities)\n",
    "    \n",
    "    # 2nd part: cmmd\n",
    "    final_output = continual_multiplex_analysis(nodelist=nodelist,\n",
    "                                                path_to_communities=path_to_communities,\n",
    "                                                distmethod=distmethod,\n",
    "                                                n_jobs=n_jobs)\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"../data/bsc_baseline_tiny/\"\n",
    "prefix = \"../data/synthetic/\"\n",
    "\n",
    "input_layers = [prefix + x for x in os.listdir(prefix) if x.endswith(\".csv\")]\n",
    "\n",
    "for l in input_layers:\n",
    "    assert Path(l).exists()\n",
    "\n",
    "cmmd_output = cmmd(nodelist = None,\n",
    "     input_layers = input_layers,\n",
    "     gamma_min = 0,\n",
    "     gamma_max = 30,\n",
    "     gamma_step = 0.5,\n",
    "     path_to_communities = \"../out/communities/\",\n",
    "     distmethod = \"hamming\",\n",
    "     n_jobs = 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean folder that contains the gerated files of the communities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN = False\n",
    "folder_path = Path(\"../out/communities/\")\n",
    "\n",
    "if CLEAN:\n",
    "    for item in os.listdir(folder_path):\n",
    "        shutil.rmtree(os.path.join(folder_path, item)) if os.path.isdir(os.path.join(folder_path, item)) else os.remove(os.path.join(folder_path, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save object to the disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save object to file\n",
    "# path_save = Path(\"../out/cmmd_pickle/\")\n",
    "# assert path_save.exists()\n",
    "\n",
    "# # pickle the object\n",
    "# with open(path_save / \"cmmd_output.pkl\", 'wb') as handle:\n",
    "#     pickle.dump(cmmd_output, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_cmmd(cmmd:dict, path_save:pathlib.Path|str=Path(\"../out/cmmd_pickle/cmmd_output.pkl\")) -> None:\n",
    "#     # load the cmmd object\n",
    "#     with open(path_save, 'rb') as handle:\n",
    "#         cmmd_old = pickle.load(handle)\n",
    "#     assert (cmmd[\"distance_matrix\"] == cmmd_old[\"distance_matrix\"]).all()\n",
    "#     assert (cmmd[\"gene_community_matrix\"] == cmmd_old[\"gene_community_matrix\"]).all()\n",
    "#     assert cmmd[\"l_constant\"] == cmmd_old[\"l_constant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm new and old objects generate the same output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "cmmd_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmmd_output[\"distance_matrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "for key in cmmd_output.keys():\n",
    "    print(key)\n",
    "    print(cmmd_output[key])\n",
    "    print(\"*\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "cmmd_output[\"distance_matrix\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dm = cmmd_output[\"distance_matrix\"]\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "np.unique(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "sns.histplot(cmmd_output[\"distance_matrix\"].flatten(), stat=\"density\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "gcm = cmmd_output[\"gene_community_matrix\"]\n",
    "gcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "gcm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "l_constant = cmmd_output[\"l_constant\"]\n",
    "type(l_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "len(l_constant.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmmd_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
